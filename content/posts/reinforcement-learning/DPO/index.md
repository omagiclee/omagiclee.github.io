+++
date = '2023-05-29T20:20:00+08:00'
draft = false
title = 'Direct Preference Optimization (DPO): Your Language Model is Secretly a Reward Model'
categories = ['Reinforcement Learning']
tags = ['Reinforcement Learning']
+++

:(fas fa-award fa-fw):<span style="color:gray"></span>
:(fas fa-building fa-fw):<span style="color:gray"></span>
:(fas fa-file-pdf fa-fw):[arXiv 2305.18290](https://arxiv.org/abs/2305.18290)
:(fab fa-github fa-fw):[]()
<img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face" style="height: 0.9em; vertical-align: -0.15em; margin-right: 2px;">[]()
:(fas fa-globe fa-fw):[]()
:(fas fa-blog fa-fw):[]()

## TL;DR

<span style="color:red;"></span>

## Motivations & Innovations

## Approach

### Model

### Training Recipe

### Data Recipe

## Experiments


